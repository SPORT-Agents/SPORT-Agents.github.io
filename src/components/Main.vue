<template>
  <div class="research-bar">
    <span class="research-title">More Research:</span>
    <div class="research-link-wrapper">
      <a class="research-link" href="https://clova-tool.github.io/" target="_blank">
        CLOVA <span class="conf-tag">[CVPR 2024]</span>
      </a>
      <div class="preview-popup">
        <iframe src="https://clova-tool.github.io/" frameborder="0"></iframe>
      </div>
    </div>
    <div class="research-link-wrapper">
      <a class="research-link" href="https://mm-fire.github.io/#" target="_blank">
        FIRE <span class="conf-tag">[NeurIPS 2024]</span>
      </a>
      <div class="preview-popup">
        <iframe src="https://mm-fire.github.io/#" frameborder="0"></iframe>
      </div>
    </div>
    <div class="research-link-wrapper">
      <a class="research-link" href="https://mat-agent.github.io/" target="_blank">
        MAT <span class="conf-tag">[ICLR 2025]</span>
      </a>
      <div class="preview-popup">
        <iframe src="https://mat-agent.github.io/" frameborder="0"></iframe>
      </div>
    </div>
    <div class="research-link-wrapper">
      <a class="research-link" href="https://tongui-agent.github.io/" target="_blank">
        TongUI <span class="conf-tag">[Arxiv]</span>
      </a>
      <div class="preview-popup">
        <iframe src="https://tongui-agent.github.io/" frameborder="0"></iframe>
      </div>
    </div>
    <div class="research-link-wrapper">
      <a class="research-link" href="https://computer-use-agents.github.io/macos/" target="_blank">
        MacOS Agent <span class="conf-tag">[Open-source Project]</span>
      </a>
      <div class="preview-popup">
        <iframe src="https://computer-use-agents.github.io/macos/" frameborder="0"></iframe>
      </div>
    </div>
  </div>

  <head>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <!-- <meta charset="UTF-8"> -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  </head>
  <div class="main">
    <div class="section header">
      <div class="title">
        <img class="mat-icon" src="/icon2.png" alt="SPORT icon">
        SPORT
      </div>
      <div class="subtitle">
        Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning
      </div>


      <div class="author-list">
        <span class="author">
          <el-link href="https://pengxiang-li.github.io">Pengxiang Li</el-link>
          <span class="ind">1,2 &#9733;</span>,
        <span class="author">
          <el-link href="https://zhigao2017.github.io/">Zhi Gao</el-link>
          <span class="ind">2,3 &#9733;</span>,
        </span>
        <span class="author">
          <el-link href="https://bofei5675.github.io/">Bofei Zhang</el-link>
          <span class="ind">2 </span>,
        </span>
        <span class="author">
          <el-link href="https://scholar.google.com/citations?user=xr7kNGEAAAAJ&hl">Yapeng Mi</el-link>
          <span class="ind">2,4</span>,
        </span>
        </span>
        <span class="author">
          <el-link href="https://jeasinema.github.io/">Xiaojian Ma</el-link>
          <span class="ind">2</span>,
        </span>
        <span class="author">
          <el-link href="https://scholar.google.com/citations?user=DSN0fGIAAAAJ&hl=en">Chenrui Shi</el-link>
          <span class="ind">1,2</span>,
        </span>
        <br>
        <span class="author">
          <el-link href="https://i.yt.sb/">Tao Yuan</el-link>
          <span class="ind">2</span>,
        </span>
        <span class="author">
          <el-link href="https://wu-yuwei-bit.github.io/">Yuwei Wu</el-link>
          <span class="ind">&#9993;1,5</span>,
        </span>
        

        <span class="author">
          <el-link href="https://scholar.google.com/citations?user=Sl6TV7gAAAAJ&hl=en">Yunde Jia</el-link>
          <span class="ind">5</span>,
        </span>
        <span class="author">
          <el-link href="https://www.zhusongchun.net/">Song-Chun Zhu</el-link>
          <span class="ind">2,3,6</span>,
        </span>
        <span class="author">
          <el-link href="https://liqing.io/">Qing Li</el-link>
          <span class="ind">&#9993;2</span>
        </span>
      </div>
      <div class="author-list">
        <span class="org">
          <span class="ind">1</span>
          Beijing Institute of Technology
        </span>
        <span class="org">
          <span class="ind">2</span>
          Beijing Institute for General Artificial Intelligence
        </span>
        <br>
        <span class="org">
          <span class="ind">3</span>
          Peking University 
        </span>
        <span class="org">
          <span class="ind">4</span>
          Harbin Institute of Technology
        </span>
        <span class="org">
          <span class="ind">5</span>
          Shenzhen MSU-BIT University
        </span>
        <span class="org">
          <span class="ind">6</span>
          Tsinghua University
        </span>
      </div>

      <span class="link-block">
        <a href="https://arxiv.org/pdf/2504.21561" class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" width="1.0em" height="1.0em" viewBox="0 0 24 24">
              <path fill="currentColor"
                d="M3.842 0a1 1 0 0 0-.922.608c-.153.369-.044.627.294 1.111l6.919 8.36l-1.023 1.106a1.04 1.04 0 0 0 .003 1.423l1.23 1.313l-5.44 6.444c-.28.3-.453.823-.297 1.199a1.025 1.025 0 0 0 .959.635a.91.91 0 0 0 .689-.34l5.783-6.126l7.49 8.005a.85.85 0 0 0 .684.26a.96.96 0 0 0 .877-.615c.158-.377-.017-.75-.306-1.14L13.73 13.9l1.064-1.13a.963.963 0 0 0 .009-1.316L4.633.464S4.26.01 3.867 0zm0 .272h.017c.218.005.487.272.564.364l.005.006l.005.005l10.17 10.99a.69.69 0 0 1-.008.946l-1.066 1.133l-1.498-1.772l-8.6-10.39c-.328-.472-.352-.619-.26-.841a.73.73 0 0 1 .671-.44Zm14.341 1.57a.88.88 0 0 0-.655.242l-5.696 6.158l1.694 1.832l5.309-6.514c.325-.433.479-.66.325-1.029a1.12 1.12 0 0 0-.977-.689m-7.655 12.282l1.318 1.414l-5.786 6.13a.65.65 0 0 1-.496.26a.75.75 0 0 1-.706-.467c-.112-.269.036-.687.244-.909l.005-.005l.005-.006z" />
            </svg>
          </span>
          <span>arXiv</span>
        </a>
      </span>
      <span class="link-block">
        <a href="https://github.com/SPORT-Agents/SPORT-Agents" class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <i class="fab fa-github"></i>
          </span>
          <span>Code</span>
        </a>
      </span>

      <!-- Data Link. need changing -->
      <span class="link-block">

        <a target="_blank" href="https://huggingface.co/datasets/PengxiangLi/SPORT/"
          class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <i class="fa fa-database"></i>
          </span>
          <span>Data</span>
        </a>
      </span>

      <!-- <span class="link-block">

        <a target="_blank" href="https://www.youtube.com/watch?v=CHtvtR5y8so"
          class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="20" height="20" viewBox="2 0 32 22"
            style="fill:#EBEBEB;">
            <path d="M30.362,8.749c-0.218-1.179-0.989-2.168-2.064-2.647c-0.508-0.228-1.096,0.002-1.32,0.506	c-0.226,0.505,0.001,1.096,0.506,1.32c0.473,0.211,0.814,0.654,0.912,1.185c0.005,0.029,0.009,0.058,0.014,0.087	c0.001,0.093,0.014,0.185-0.002,0.28c-0.145,0.815-0.918,1.362-1.738,1.217c-6.302-1.111-13.09-1.128-20.188-0.053	c-0.518,3.798-0.475,8.104,0.132,11.988c0.127,0.818-0.433,1.586-1.251,1.714c-0.078,0.012-0.156,0.018-0.233,0.018	c-0.361,0-0.699-0.131-0.962-0.353c-0.003-0.002-0.006-0.004-0.008-0.006c-0.119-0.101-0.217-0.226-0.3-0.361	c-0.01-0.017-0.025-0.03-0.035-0.047c-0.085-0.151-0.146-0.319-0.175-0.501c-0.71-4.556-0.697-9.662,0.035-14.01	c0.106-0.632,0.603-1.126,1.233-1.23c0.437-0.073,0.871-0.132,1.306-0.197c5.965-0.766,11.879-0.861,17.592-0.262	c0.567,0.064,1.041-0.342,1.099-0.89c0.058-0.55-0.341-1.042-0.89-1.099C17.738,4.749,11.227,4.896,4.668,5.841	C3.156,6.06,1.93,7.259,1.685,8.759c-0.808,4.979-0.822,9.893-0.043,14.604c0.266,1.597,1.546,2.835,3.113,3.013	c3.665,0.414,7.384,0.621,11.132,0.621c3.772,0,7.575-0.21,11.379-0.63c1.547-0.172,2.827-1.378,3.113-2.934	C31.271,18.569,31.266,13.628,30.362,8.749z M13,13.958c0-0.879,0.944-1.434,1.712-1.007l5.475,3.042c0.79,0.439,0.79,1.576,0,2.015	l-5.475,3.042C13.944,21.476,13,20.92,13,20.042V13.958z"></path>
            </svg>
          </span>
          <span>Video</span>
        </a>
      </span> -->
      <span class="link-block">
     
        <a target="_blank" href="https://huggingface.co/li-qing/llava-next-llama3-8b-student-fire/tree/main"
          class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <i class="fa fa-share-square"></i>
          </span>
          <span>Model</span>
        </a>
      </span>
      <!-- <span class="link-block">
 
        <a target="_blank" href="https://li-qing-fire.hf.space"
          class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <i class="fa fa-images"></i>
          </span>
          <span>Demo</span>
        </a>
      </span> -->
      <!-- <span class="link-block">
 
        <a target="_blank" href="https://x.com/Sealiqing/status/1819279627438973133"
          class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
<svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="1.0em" height="1.0em" viewBox="0,0,256,256">
<g fill="#e9e9e9" fill-rule="nonzero" stroke="none" stroke-width="1" stroke-linecap="butt" stroke-linejoin="miter" stroke-miterlimit="10" stroke-dasharray="" stroke-dashoffset="0" font-family="none" font-weight="none" font-size="none" text-anchor="none" style="mix-blend-mode: normal"><g transform="scale(5.12,5.12)"><path d="M6.91992,6l14.2168,20.72656l-14.9082,17.27344h3.17773l13.13867,-15.22266l10.44141,15.22266h10.01367l-14.87695,-21.6875l14.08008,-16.3125h-3.17578l-12.31055,14.26172l-9.7832,-14.26172z"></path></g></g>
</svg>
          </span>
          <span>Twitter</span>
        </a>
      </span> -->
      <!-- <span class="link-block">
            <a href="file/clova_cvpr24_poster.pdf"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <i class="fas fa-file-pdf"></i>
              </span>
              <span>Poster (CVPR'24)</span>
            </a>
          </span> -->

      <!-- <span class="link-block">
            <a href="file/clova_slides.pdf"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <i class="fas fa-file-pdf"></i>
              </span>
              <span>Slides</span>
            </a>
          </span> -->

    </div>


    <div class="tldr">
      <p><b>TL;DR</b> This paper introduces an online self-exploration loop that enables multimodal agents to self-improve via AI-generated tasks and LLM-verified preference tuning without human annotations.</p>
    </div>

    <div class="section">
      <el-card class="teaser">
        <el-image src="./stats/visualization2-2.jpg"></el-image>
      </el-card>
    </div>


    <div class="section">
      <div class="section-title">Introduction</div>
      <p class="intro">
        Multimodal agents, which integrate a controller (e.g., a large language model) with external tools, have demonstrated remarkable capabilities in tackling complex tasks. However, existing agents need to collect a large number of expert data for fine-tuning to adapt to new environments. In this paper, we propose an online self-exploration method for multimodal agents, namely SPORT, via <span class="uns">S</span>tep-wise <span class="uns">P</span>reference <span class="uns">O</span>ptimization to <span class="uns">R</span>efine the <span class="uns">T</span>rajectories of agents, which automatically generates tasks and learns from solving the generated tasks, without any expert annotation. SPORT operates through four iterative components: task synthesis, step sampling, step verification, and preference tuning. First, we synthesize multimodal tasks using language models. Then, we introduce a novel search scheme, where step sampling and step verification are executed alternately to solve each generated task. We employ a verifier to provide AI feedback to construct step-wise preference data. The data is subsequently used to update the controller's policy through preference tuning, producing a SPORT Agent. By interacting with real environments, the SPORT Agent evolves into a more refined and capable system. Evaluation in the GTA and GAIA benchmarks shows that the SPORT Agent achieves 6.41% and 3.64% improvements, underscoring the generalization and effectiveness introduced by our method.
      </p>
    </div>




    <!-- <video width="80%" height=auto controls="/poster.png">
      <source src="/mat-video.mp4" type="video/mp4">
    </video> -->

    <div class="section">
      <el-card class="poster">
        <el-image src="/poster.png"></el-image>
      </el-card>
    </div>


    <div class="section">
      <div class="section-title">Iterative Trajectory Generation</div>
      <el-card class="teaser">
        <el-image src="./abstract.jpg"></el-image>
      </el-card>
      <p class="intro">SPORT proceeds through a detailed four‐step loop in each iteration:</p>
      <ol style="margin-left: 0; text-align: left;">
        <li style="margin-bottom: 0.5em;">
          <strong>Task Generation:</strong>  
          The agent autonomously synthesizes a new multimodal challenge by defining both the objective (for example, a coding problem or a tool‐use scenario) and the contextual inputs it will encounter.
        </li>
        <li style="margin-bottom: 0.5em;">
          <strong>Step Sampling:</strong>  
          At each decision point within the generated task, the current policy proposes several candidate actions. It executes each action in the environment and gathers the resulting observations for later evaluation.
        </li>
        <li style="margin-bottom: 0.5em;">
          <strong>Step Verification:</strong>  
          An open-source LLM serves as a critic to compare the outcomes of the sampled actions. It ranks them and selects the single most promising step, treating the other candidates as dispreferred and creating step‐wise preference pairs.
        </li>
        <li style="margin-bottom: 0.5em;">
          <strong>Preference Tuning:</strong>  
          All collected preference comparisons are aggregated into a training dataset. The agent then updates its policy via a preference‐based optimization procedure—referencing the previous policy—to increase the likelihood of the preferred actions over the alternatives.
        </li>
      </ol>
      <p class="intro">After tuning, the updated policy becomes the new reference, and the entire cycle—task generation, step sampling, LLM verification, and preference‐driven refinement—repeats until the agent's performance stabilizes and converges.</p>
      <el-card class="teaser">
        <el-image src="./stats/intro.jpg"></el-image>
      </el-card>

    </div>


    <!-- <div class="section">
      <div class="section-title">MM-Traj Dataset </div>
      <div class="intro">Data that passes through the two verifiers is considered high-quality and collected in an
        MM-Traj
        dataset. In summary, we collect <b>23.5K data points</b> from query generation and file generation. After
        passing through the two verifiers, <b>20K data points</b> are left with <b>15K files</b>. </div>
      <p>Notable statistics of <img class="mat-icon" src="/icon2.png"><b>MM-Traj</b></p>

      <br>
      <el-card class="teaser">
        <el-image src="./stats/stats-mm-traj.png"></el-image>
      </el-card>
    </div> -->




    <div class="section">
      <div class="section-title">
        <svg t="1735026864471" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg"
          p-id="2411" width="35" height="35">
          <path
            d="M847.40096 805.88416c8.92544 8.92544 8.92544 23.00032-0.2752 32.50048a22.95552 22.95552 0 0 1-31.97696-0.54912L674.84288 697.78304a22.72512 22.72512 0 0 1 0.5248-32.22528c8.704-8.65024 23.296-8.65024 32.52608 0l139.5072 140.3264zM785.34784 15.4624a188.09216 188.09216 0 0 1 44.17664 4.62976 195.55456 195.55456 0 0 1 43.07712 13.00096 38.23744 38.23744 0 0 1 19.776 50.10176 40.4096 40.4096 0 0 1-7.87456 11.92576c-28.97664 28.97536-57.95328 57.6768-86.70464 86.67776l4.89984 17.3248 4.32512 17.6256 17.87648 4.84992 17.3504 4.60032c28.70144-28.97536 57.7024-57.42592 86.67904-86.67776 14.62656-14.90048 39.0016-14.90048 54.17856 0a38.84544 38.84544 0 0 1 9.19936 16.256 197.32992 197.32992 0 0 1 11.648 38.47552v0.5504h0.2752a229.60768 229.60768 0 0 1 4.32512 44.40192 223.29728 223.29728 0 0 1-223.20768 222.92096c-4.32512 0-8.65024-0.2752-13.00096-0.2752l-42.25152 41.728 232.41088 232.40576 1.89952 2.1504a156.99456 156.99456 0 0 1-1.89952 220.23168l-0.5504 0.5248a156.69632 156.69632 0 0 1-110.50496 45.52064c-40.0768 0-80.9792-15.1744-111.05536-46.05056L507.45984 725.68448 269.87392 963.79136c-49.55264 49.55136-109.43104 53.9264-158.464 32.77568a155.91936 155.91936 0 0 1-50.09408-33.8752h-0.27648a158.7584 158.7584 0 0 1-33.57696-49.82656c-21.15072-49.024-16.80128-109.15328 33.024-158.48064v-0.5248L325.4016 488.95616l-96.95488-96.97792-86.12864-25.728a37.59744 37.59744 0 0 1-24.37632-21.4016L35.28704 151.16416a38.048 38.048 0 0 1 6.77504-44.40064l34.67776-34.39872 34.15168-34.1504a37.67552 37.67552 0 0 1 41.70112-8.12544l196.11008 83.72736a37.43616 37.43616 0 0 1 21.67552 24.37632l25.45152 86.12736 96.97408 96.95616 69.632-69.05216c-0.2752-4.89984-0.5248-9.50016-0.5248-13.02528h0.2496a222.2208 222.2208 0 0 1 65.28-158.17984v-0.27904a224.13952 224.13952 0 0 1 157.9072-65.28zM675.9424 557.7536l-114.3296 114.3296 232.4352 232.40704a80.75904 80.75904 0 0 0 114.304 0.2496l0.5248-0.2496c15.72608-15.17568 23.0272-36.608 23.0272-57.1776a79.96416 79.96416 0 0 0-21.952-55.5264l-1.6-1.62432-232.4096-232.40832z m-296.88832-122.45248l59.8528-59.5776-103.72992-104.00256a38.33984 38.33984 0 0 1-10.30144-18.976l-22.49984-76.12672L146.368 110.816 130.39232 126.5408l-15.97568 16.256 66.32832 156.032 78.5536 23.00032a33.73056 33.73056 0 0 1 16.2752 10.02624l103.48032 103.45344z m400.896-343.43552a145.92 145.92 0 0 0-98.60224 43.32544 145.408 145.408 0 0 0-43.32672 104.00384h0.5248v10.57536l1.0752 8.92544c2.72512 11.92448-1.0752 24.94976-10.27584 34.432L114.41664 807.76192h-0.2752c-23.82592 24.65024-26.55104 52.55168-16.80128 75.5776a93.87136 93.87136 0 0 0 17.60128 25.472 87.296 87.296 0 0 0 26.00064 17.6c23.02592 10.02496 50.65216 7.296 75.05408-16.5248l263.83744-263.8336 1.0752-1.0752 167.936-168.2048 1.0752-1.37472 80.7296-80.17792h0.2496a36.23808 36.23808 0 0 1 32.256-11.10016 79.7696 79.7696 0 0 0 11.40096 1.09952c2.6752 0.2752 6.47552 0.5248 10.80064 0.5248a148.64128 148.64128 0 0 0 104.02944-42.52544v-0.5248a145.73568 145.73568 0 0 0 42.51904-98.60224c-16.52608 16.77568-33.05216 33.024-49.57824 50.10176-9.45024 10.54976-23.82592 14.90048-38.4512 11.62496l-38.4768-10.52544-38.97728-10.57536c-13.02528-3.52512-23.57632-12.99968-27.10144-27.10016l-10.30016-38.99776-10.57536-39.0016c-2.944-11.92448-0.2752-26.55104 10.02496-36.0256 17.07648-17.32608 34.15168-34.40128 51.47776-51.72736z"
            fill="#3B3F51" p-id="2412"></path>
        </svg> Tools in SPORT-Agent
      </div>
      <p class="intro">
        Following <el-link href="https://mat-agent.github.io" style="color: purple; font-size: 1.2em;">MAT</el-link>, we deploy <b>real-executable tools</b> for the agent instead of only providing tool names. Our tools are across
        multiple categories: web search, visual perception, image generation/editing, file understanding, multi-modal
        understanding, and multiple Python packages.
      </p>
      <el-image class="stats-img" src="./stats/tools.png" style="width: 73%;"></el-image>
    </div>

    <!-- <div class="section">
      <div class="section-title">MM-Traj Dataset </div>
      <div class="intro">Data that passes through the two verifiers is considered high-quality and collected in an
        MM-Traj
        dataset. In summary, we collect <b>23.5K data points</b> from query generation and file generation. After
        passing through the two verifiers, <b>20K data points</b> are left with <b>15K files</b>. </div>
      <p>Notable statistics of <img class="mat-icon" src="/icon2.png"><b>MM-Traj</b></p>

      <br>
      <el-card class="teaser">
        <el-image src="./stats/stats-mm-traj.png"></el-image>
      </el-card>
    </div> -->

    <div class="section">
      <div class="section-title">Evaluation and Results </div>
      <div class="intro">We evaluate the <b>SPORT Agent</b> on two benchmarks: <b>GTA</b> and <b>GAIA</b>. The results show that the SPORT Agent outperforms SFT baselines by <b>6.41%</b> on GTA and <b>3.64%</b> on GAIA, demonstrating that its online self-exploration loop with LLM‐guided step verification and preference tuning produces high-quality in-distribution preference data that substantially boosts tool usage and code execution success.<br></div>

      <div class="intro"><b>Metrics.</b> In the <b>GTA</b> benchmark, we measure three metrics: <i><b>AnsAcc</b></i> (answer correctness), <i><b>ToolAcc</b></i> (tool selection and answer summary accuracy), and <i><b>CodeExec</b></i> (percentage of error-free code execution). In the <b>GAIA</b> benchmark, we measure <i><b>AnsAcc</b></i> across three difficulty levels.<br><br></div>

      <div class="intro"><b>Results.</b> As shown in the table below, our <b>SPORT Agent</b> achieves significant improvements across both benchmarks. On GTA, it outperforms SFT-based T3-Agent by <b>+7%</b> in <i><b>AnsAcc</b></i>, <b>+8%</b> in <i><b>ToolAcc</b></i>, and <b>+7%</b> in <i><b>CodeExec</b></i>. Even compared to HF agent using GPT-4o, our agent achieves <b>higher <i>ToolAcc</i></b> with <i>comparable CodeExec</i>. On GAIA, <b>SPORT Agent</b> achieves the <b>best results among open-source models</b>, outperforming Qwen2-VL-7B by <b>+11%</b> on <i><b>AnsAcc</b></i> and improving <b>+4%</b> over the SFT-tuned MAT-Qwen2-VL-7B. These consistent improvements across all difficulty levels highlight the effectiveness of our online self-exploration framework.<br><br></div>

      <el-card class="stats-img-1">
        <el-image src="./stats/main_result.png"></el-image>
      </el-card>
    </div>


  </div>

  <div class="section">
    <div class="section-title">Visualization</div>
    <p class="intro">
      We visualize the preference data generated by our online
self-exploration framework. The <b>verifier successfully identifies solutions</b> that produce correct
intermediate results. In <b>step 1</b>, the solution that generates the
correct brand and basic information about the smartphone
is selected as the preferred data. In <b>step 2</b>, the solution that
searches for content most relevant to the task is preferred—specifically, 
one that compares the smartphone with <b>mid-range competitors</b>, 
rather than comparing it with a specialized device.
    </p>
    <el-card class="stats-img-2">
      <el-image src="./stats/visualization1.jpg"></el-image>
    </el-card>
  </div>
  <div class="section">
    <div class="section-title">Ablation</div>
    <p class="intro">
      Our ablation study on the GTA benchmark examines the impact of iteration step size <i>d</i> ∈ {200, 500, 1000}. <b>Setting <i>d</i> = 500 achieves the best performance</b> across all metrics. Larger steps (<i>d</i> = 1000) limit adaptability, while smaller steps (<i>d</i> = 200) reduce data diversity. A moderate step size provides optimal balance between update frequency and diversity for effective training.
    </p>
    <br><br>
    <el-card class="stats-img-2" style="max-width: 60%; margin: 0 auto;">
      <el-image src="./stats/ablation_d.png" style="width: 100%;"></el-image>
    </el-card>
  </div>



  <div class="section"> 
    <div class="section-title">Data Quality</div>
    <p class="intro">
      We conducted a user study with 20 AI researchers to evaluate our preference data quality. Participants assessed tasks and trajectories on five criteria: Reasonableness, Naturalness, Code accuracy, Tool selection, and Parameter passing. <b>Results showed average scores exceeding 8/10</b> across all criteria, validating our approach.
      
      In a separate study with 20 different researchers evaluating 50 sampled steps, we found <b>82% agreement</b> between our verifier's preferences and human judgments. This high overlap confirms that our automated verifier effectively captures human-like preferences for code accuracy, tool selection, and parameter correctness.
    </p>
    <br><br>
    <el-card class="stats-img-2" style="max-width: 60%; margin: 0 auto;">
      <el-image src="./stats/data_quality.png" style="width: 100%;"></el-image>
    </el-card>
  </div>
  <section class="section" id="BibTeX" style="text-align: left;">
    <div class="container is-max-desktop content" style="max-width: 100%; margin: 0 auto;">
      <h3 class="title" style="font-size: small;">
        BibTeX
      </h3>
      <div class="bibtex-container">
        <pre><code class="language-bibtex">
    @inproceedings{li2025iterative,
      title={Iterative Trajectory Exploration for Multimodal Agents}, 
      author={Li, Pengxiang and Gao, Zhi and Zhang, Bofei and Mi, Yapeng and Ma, Xiaojian and Shi, Chenrui and Yuan, Tao and Wu, Yuwei and Jia, Yunde and Zhu, Song-Chun and Li, Qing},
      year={2025},
      eprint={2504.21561},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/2504.21561}, 
      }
</code></pre>
      </div>
    </div>
  </section>


  <div class="footer">
    This website is inspired by <el-link href="https://mathvista.github.io/">MathVista</el-link> and <el-link
      href="https://nerfies.github.io/">Nerfies</el-link>.
  </div>
</template>

<script setup>
// import Dialog from './Dialog.vue'

import { onMounted, ref } from 'vue'

const dataset1 = ref([])
const loadData1 = async () => {
  const resp1 = await fetch('./data/demo-100k.json')
  dataset1.value = await resp1.json()
}

const dataset2 = ref([])
const loadData2 = async () => {
  const resp2 = await fetch('./data/demo-1m.json')
  dataset2.value = await resp2.json()
}

const dataset3 = ref([])
const loadData3 = async () => {
  const resp3 = await fetch('./data/demo-bench.json')
  dataset3.value = await resp3.json()
}

onMounted(() => {
  loadData1(),
    loadData2(),
    loadData3()
})
</script>






<style scoped>
.main {
  text-align: center;
  color: #23272f;
  font-family: 'Inter', 'Helvetica Neue', Arial, sans-serif;
  max-width: 1300px;
  margin: 0 auto;
  padding: 0 24px;
  background: linear-gradient(120deg, #f8fbff 0%, #f3f6fa 100%);
}

.header {
  margin: 56px 0 32px 0 !important;
}

.title {
  font-size: 3.8em;
  font-weight: 800;
  color: #1a237e;
  letter-spacing: -1px;
  margin-bottom: 8px;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 16px;
}

.subtitle {
  font-size: 2.1em;
  color: #374151;
  font-weight: 500;
  line-height: 1.3;
  max-width: 1100px;
  margin: 0 auto 12px auto;
  letter-spacing: 0.01em;
}

.author-list {
  margin: 18px 0 0 0;
  line-height: 1.7;
  font-size: 1.08em;
  color: #2b3a4b;
}

.author a {
  font-size: 1em;
  font-weight: 600;
  color: #1976d2;
  text-decoration: none;
  border-bottom: 1px dotted #90caf9;
  transition: color 0.2s, border-bottom 0.2s;
}
.author a:hover {
  color: #0d47a1;
  border-bottom: 1px solid #1976d2;
}

.org {
  margin: 0 4px;
  color: #607d8b;
  font-size: 0.98em;
}

.ind {
  font-size: 0.7em;
  vertical-align: super;
  color: #90a4ae;
}

.section {
  margin: 36px 0;
  padding: 0 10px;
}

.tldr {
  text-align: left;
  font-size: 1.08em;
  max-width: 1100px;
  line-height: 1.6;
  margin: 28px auto 24px auto;
  padding: 18px 24px;
  background: linear-gradient(90deg, #e3f0fc 0%, #f5fafd 100%);
  border-left: 4px solid #1976d2;
  border-radius: 8px;
  box-shadow: 0 2px 8px 0 rgba(25, 118, 210, 0.04);
}

.section-title {
  margin: 32px 0 18px;
  font-size: 1.7em;
  font-weight: 700;
  color: #1a237e;
  text-align: left;
  letter-spacing: 0.01em;
}

.conference {
  text-align: center;
  margin: 15px;
  font-size: 1.2em;
  color: #666;
}

.uns {
  text-decoration: underline;
  text-decoration-color: #1976d2;
}

.mat-icon {
  width: 1.3em;
  height: 1.3em;
  margin-right: 0.1em;
  vertical-align: middle;
  display: inline-block;
}

.teaser, .poster, .stats-img-1 {
  max-width: 98%;
  margin: 24px auto;
  border-radius: 12px;
  background: #fff;
  box-shadow: 0 2px 12px 0 rgba(25, 118, 210, 0.06);
  border: 1px solid #e3eaf2;
  overflow: hidden;
}

.stats-img {
  height: auto;
  max-width: 100%;
  margin: 15px auto;
}

.intro {
  text-align: justify;
  font-size: 1.08em;
  max-width: 1100px;
  line-height: 1.6;
  margin: 0 auto 12px auto;
  color: #23272f;
}

.link-block {
  margin: 18px 0;
}

.external-link {
  display: inline-flex;
  align-items: center;
  padding: 10px 22px;
  margin: 6px;
  border: none;
  border-radius: 6px;
  background: linear-gradient(90deg, #1976d2 0%, #64b5f6 100%);
  color: #fff;
  text-decoration: none;
  font-size: 1em;
  font-weight: 600;
  box-shadow: 0 2px 8px 0 rgba(25, 118, 210, 0.08);
  transition: background 0.2s, box-shadow 0.2s, transform 0.1s;
}
.external-link:hover {
  background: linear-gradient(90deg, #1565c0 0%, #42a5f5 100%);
  box-shadow: 0 4px 16px 0 rgba(25, 118, 210, 0.13);
  transform: translateY(-2px) scale(1.03);
}
.external-link .icon {
  margin-right: 10px;
  color: #e3f2fd;
}

.bibtex-container {
  background: #f5fafd;
  padding: 1.2em;
  border-radius: 8px;
  text-align: left;
  white-space: pre;
  overflow-x: auto;
  border: 1px solid #e3eaf2;
  margin: 18px 0;
}

pre {
  margin: 0;
  font-family: 'Fira Mono', 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
}

code {
  font-family: 'Fira Mono', 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
  color: #23272f;
  font-size: 0.98em;
}

.footer {
  color: #90a4ae;
  margin: 60px 0 30px;
  font-size: 0.98em;
  text-align: center;
}
.footer a {
  color: #1976d2;
  text-decoration: none;
  border-bottom: 1px dotted #90caf9;
  transition: color 0.2s, border-bottom 0.2s;
}
.footer a:hover {
  color: #0d47a1;
  border-bottom: 1px solid #1976d2;
}

@media (max-width: 900px) {
  .main {
    max-width: 100vw;
    padding: 0 6px;
  }
  .title {
    font-size: 2.2em;
  }
  .subtitle {
    font-size: 1.1em;
  }
  .section {
    padding: 0 2px;
  }
  .stats-img-1, .teaser, .poster {
    max-width: 100%;
  }
  .tldr, .intro {
    max-width: 98vw;
  }
}

.research-bar {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 18px;
  padding: 18px 0 8px 0;
  background: transparent;
  font-size: 1.08em;
  flex-wrap: wrap;
  position: relative;
}
.research-title {
  color: #1976d2;
  font-weight: 700;
  margin-right: 8px;
}
.research-link {
  display: inline-flex;
  align-items: center;
  padding: 6px 16px;
  border-radius: 6px;
  background: #e3f0fc;
  color: #1a237e;
  text-decoration: none;
  font-weight: 600;
  margin: 0 2px;
  transition: background 0.18s, color 0.18s, box-shadow 0.18s;
  box-shadow: 0 1px 4px 0 rgba(25, 118, 210, 0.06);
}
.research-link:hover {
  background: #1976d2;
  color: #fff;
  box-shadow: 0 2px 8px 0 rgba(25, 118, 210, 0.13);
}
.conf-tag {
  font-size: 0.95em;
  font-weight: 400;
  color: #1976d2;
  background: #e3f0fc;
  border-radius: 4px;
  padding: 2px 6px;
  margin-left: 6px;
  transition: color 0.18s, background 0.18s;
}
.research-link:hover .conf-tag {
  color: #fff;
  background: #1565c0;
}
.research-link-wrapper {
  position: relative;
  display: inline-block;
}
.preview-popup {
  display: none;
  position: absolute;
  left: 50%;
  top: 110%;
  transform: translateX(-50%);
  width: 1000px;
  height: 600px;
  background: rgba(255,255,255,0.95);
  border-radius: 10px;
  box-shadow: 0 8px 32px 0 rgba(25, 118, 210, 0.18);
  z-index: 100;
  opacity: 0;
  pointer-events: none;
  transition: opacity 0.25s;
  overflow: hidden;
}
.research-link-wrapper:hover .preview-popup {
  display: block;
  opacity: 1;
  pointer-events: auto;
}
.preview-popup iframe {
  width: 100%;
  height: 100%;
  border: none;
  opacity: 0.85;
  border-radius: 10px;
}
@media (max-width: 900px) {
  .preview-popup {
    display: none !important;
  }
}
</style>
